{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc048249-98ab-40c9-933f-d507b45dfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table contents\n",
    "item_table = {\n",
    "    'Business': 'Item 1.',\n",
    "    'Risk Factors': 'Item 1A.',\n",
    "    'Unresolved Staff Comments': 'Item 1B.',\n",
    "    'C': 'Item 1C.',\n",
    "    'Properties': 'Item 2.',\n",
    "    'Legal Proceedings': 'Item 3.',\n",
    "    'Mine Safety Disclosures': 'Item 4.',\n",
    "    'Common Equity & Related Matters': 'Item 5.',\n",
    "    '[Reserved]': 'Item 6.',\n",
    "    'Managementâ€™s Discussion & Analysis': 'Item 7.',\n",
    "    'Market Risk Disclosures': 'Item 7A.',\n",
    "    'Financial Statements & Data': 'Item 8.',\n",
    "    'Accountant Changes & Disagreements': 'Item 9.',\n",
    "    'Controls and Procedures': 'Item 9A.',\n",
    "    'Other Information': 'Item 9B.',\n",
    "    'Foreign Inspection Restrictions': 'Item 9C.',\n",
    "    'Corporate Governance': 'Item 10.',\n",
    "    'Executive Compensation': 'Item 11.',\n",
    "    'Security Ownership and Management': 'Item 12',\n",
    "    'Related Transactions and Director Independence': 'Item 13',\n",
    "    'Accountant Fees and Services': 'Item 14.',\n",
    "    'Exhibit and Financial Schedules': 'Item 15.',\n",
    "    'Form 10-K Summary': 'Item 16.'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6207d6-4e4f-4637-81f8-2e83a085aecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39718db3-25f8-433f-be96-e6b9dee00107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sec_edgar_downloader import Downloader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def read_html_file(file_path):\n",
    "    \"\"\"Reads and returns the content of an HTML file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except IOError as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def write_html_file(file_path, content):\n",
    "    \"\"\"Writes content to an HTML file at the specified path.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(content.strip())\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file {file_path}: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def create_output_directory(directory):\n",
    "    \"\"\"Ensures the existence of the specified directory.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directory {directory}: {e}\")\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"\n",
    "    Sanitizes and formats the filename to avoid filesystem errors, preserving the file extension.\n",
    "    \"\"\"\n",
    "    # Split the filename from its extension\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    \n",
    "    # Remove unwanted characters from the name part, replace spaces with underscores, and remove additional dots\n",
    "    sanitized_name = re.sub(r'[^\\w_-]', '', name.replace(' ', '_').replace('.', ''))\n",
    "    filename = re.sub(r'[^\\w_.)(-]', '', sanitized_name)\n",
    "    \n",
    "    # Combine the sanitized name with the original extension\n",
    "    return f\"{sanitized_name}{ext}\"\n",
    "\n",
    "def extract_text_from_html(html_content):\n",
    "    \"\"\"Extracts visible text from HTML content using BeautifulSoup.\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        return soup.get_text(separator=' ', strip=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing HTML content: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_items_in_html(html_content, item_pattern):\n",
    "    \"\"\"Finds and returns items in HTML content based on the specified pattern.\"\"\"\n",
    "    try:\n",
    "        return re.findall(item_pattern, html_content, flags=re.IGNORECASE | re.DOTALL)\n",
    "    except re.error as e:\n",
    "        print(f\"Error in regex pattern: {e}\")\n",
    "        return []\n",
    "\n",
    "def disintegrate_file(file_path, output_dir, item=\"\"):\n",
    "    \"\"\"\n",
    "    Extracts sections from SEC filing HTML based on items and saves them as separate documents.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the SEC HTML file.\n",
    "        output_dir (str): Directory to save the output documents.\n",
    "        item (str): Specific item to extract, defaults to all items.\n",
    "    \"\"\"\n",
    "    html_content = read_html_file(file_path)\n",
    "    if html_content is None:\n",
    "        return \"Failed to read HTML file.\"\n",
    "\n",
    "    pattern = (fr\"({re.escape(item)})(.*?)(?=Item \\d+\\.|$)\" if item \n",
    "               else r\"(Item \\d+\\.)(.*?)(?=Item \\d+\\.|$)\")\n",
    "    items = find_items_in_html(html_content, pattern)\n",
    "    documents = []\n",
    "\n",
    "    for title, doc in items:\n",
    "        visible_text = extract_text_from_html(doc)\n",
    "        if visible_text and len(visible_text) > 120:\n",
    "            filename = sanitize_filename(f\"{title}.html\")\n",
    "            documents.append((filename, doc))\n",
    "\n",
    "    if not create_output_directory(output_dir):\n",
    "        return \"Failed to create output directory.\"\n",
    "\n",
    "    saved_docs_count = 0\n",
    "    for filename, doc in documents:\n",
    "        output_file_path = os.path.join(output_dir, filename)\n",
    "        if write_html_file(output_file_path, doc):\n",
    "            saved_docs_count += 1\n",
    "\n",
    "    if saved_docs_count > 0:\n",
    "        print(f\"{saved_docs_count} documents saved successfully.\")\n",
    "        return output_file_path\n",
    "    else:\n",
    "        return \"Failed to save any documents.\"\n",
    "\n",
    "def download_10k_filings(ticker, start_year, end_year, item_title):\n",
    "    \"\"\"\n",
    "    Downloads and processes 10-K filings from the SEC EDGAR database for a specified company and time frame.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "        start_year (int): Start year of the filing period.\n",
    "        end_year (int): End year of the filing period.\n",
    "        item_title (str): The title of the item to extract from the filings.\n",
    "    \"\"\"\n",
    "    downloader = Downloader(\"MyCompanyName\", \"my.email@domain.com\")\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        try:\n",
    "            downloader.get(\"10-K\", ticker, after=f\"{year-1}-12-31\", before=f\"{year+1}-01-01\", download_details = True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading files for year {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        filing_path = os.path.join(\"sec-edgar-filings\", ticker, \"10-K\")\n",
    "        for root, _, files in os.walk(filing_path):\n",
    "            for file in files:\n",
    "                if file == \"primary-document.html\":\n",
    "                    full_file_path = os.path.join(root, file)\n",
    "                    if item_title == \"Full Submission\":\n",
    "                        return full_file_path\n",
    "                    else:\n",
    "                        return disintegrate_file(full_file_path, root, item_table[item_title])\n",
    "    return \"No filings found or failed to process filings.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a24cc15-a233-4560-8542-31d5a60d7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 documents saved successfully.\n",
      "sec-edgar-filings\\AAPL\\10-K\\0000320193-23-000106\\Item_1.html\n"
     ]
    }
   ],
   "source": [
    "companies = [\"AAPL\"]  # Add more tickers if needed\n",
    "start_year = 2023\n",
    "end_year = 2023\n",
    "\n",
    "for company in companies:\n",
    "    print(download_10k_filings(company, start_year, end_year, 'Business' ))\n",
    "    # combine_txt_files(company,\"Revenue Recognition\")\n",
    "    # parse_files(company)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
